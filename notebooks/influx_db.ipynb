{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7606499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import influxdb_client\n",
    "from influxdb_client import InfluxDBClient, Point\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b7c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set InfluxDB connection details\n",
    "url = \"http://localhost:8086\"  # Replace with your InfluxDB URL\n",
    "token = \"c4hEuDHM9LPxNfWH-oFyFfOeIDihTnQx_OEeg99mrd6bZFNa1hEJx7a_aV-cFUH5nWquXUWU5IAeQ975itS4MQ==\"  # Replace with your InfluxDB token\n",
    "org = \"trade_smart\"  # Replace with your InfluxDB organization\n",
    "bucket = \"trade_smart\"  # Replace with your InfluxDB bucket\n",
    "\n",
    "# Instantiate the InfluxDB client\n",
    "client = InfluxDBClient(url=url, token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9461dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the write API client\n",
    "# Set InfluxDB connection details\n",
    "url = \"http://localhost:8086\"  # Replace with your InfluxDB URL\n",
    "token = \"c4hEuDHM9LPxNfWH-oFyFfOeIDihTnQx_OEeg99mrd6bZFNa1hEJx7a_aV-cFUH5nWquXUWU5IAeQ975itS4MQ==\"  # Replace with your InfluxDB token\n",
    "org = \"trade_smart\"  # Replace with your InfluxDB organization\n",
    "bucket = \"trade_smart\"  # Replace with your InfluxDB bucket\n",
    "measurement = 'candlestick'\n",
    "# Instantiate the InfluxDB client\n",
    "client = InfluxDBClient(url=url, token=token)\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8c61e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = [{\n",
    "    \"measurement\": \"candlestick\",\n",
    "    \"tags\": {\"symbol\": \"test\"},\n",
    "    \"time\": 3,\n",
    "    \"fields\": \n",
    "        {\"open\": 150.0, \"high\": 155.0, \"low\": 145.0, \"close\": 148.0, \"adj_close\": 148.0, \"volume\": 1000000}\n",
    "    }\n",
    "]\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "06d2b8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement</th>\n",
       "      <th>tags</th>\n",
       "      <th>time</th>\n",
       "      <th>fields</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>candlestick</td>\n",
       "      <td>{'symbol': 'test'}</td>\n",
       "      <td>3</td>\n",
       "      <td>{'open': 150.0, 'high': 155.0, 'low': 145.0, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   measurement                tags  time  \\\n",
       "0  candlestick  {'symbol': 'test'}     3   \n",
       "\n",
       "                                              fields  \n",
       "0  {'open': 150.0, 'high': 155.0, 'low': 145.0, '...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b7a89273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'open': 150.0, 'high': 155.0, 'low': 145.0, 'close': 148.0, 'adj_close': 148.0, 'volume': 1000000}\n"
     ]
    }
   ],
   "source": [
    "for _, row in df.iterrows():\n",
    "    print(row[\"fields\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "00f285de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point.from_dict({\n",
    "#     \"measurement\": \"candlestick\",\n",
    "#     \"tags\": {\"symbol\": \"test\"},\n",
    "#     \"time\": 1,\n",
    "#     \"fields\": \n",
    "#         {\"open\": 150.0, \"high\": 155.0, \"low\": 145.0, \"close\": 148.0, \"Adj Close\": 148.0, \"volume\": 1000000}\n",
    "#     })\n",
    "# points = []\n",
    "# for _d in data:\n",
    "#     points.append(Point.from_dict(_d))\n",
    "\n",
    "# # Convert DataFrame to InfluxDB line protocol format\n",
    "points = []\n",
    "for row in data:\n",
    "    point = Point(\"candlestick\").tag(\"symbol\", \"test\").field(\"open\", row[\"fields\"][\"open\"]).field(\"high\", row[\"fields\"][\"high\"]).field(\"low\", row[\"fields\"][\"low\"]).field(\"close\", row[\"fields\"][\"close\"]).field(\"adj_close\", row[\"fields\"][\"adj_close\"]).time(row[\"time\"])\n",
    "    points.append(point)\n",
    "# [p for p in points]\n",
    "line_protocol = \"\\n\".join([p.to_line_protocol() for p in points])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3a18a8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'candlestick,symbol=test adj_close=148,close=148,high=155,low=145,open=150 3'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e3563ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write data to InfluxDB\n",
    "write_api.write(bucket=bucket, org=org, record=line_protocol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4d492aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'from(bucket: \"{bucket}\") |> range(start: 0) |> filter(fn: (r) => r._measurement == \"{measurement}\")'\n",
    "delete_query = f'from(bucket: \"{bucket}\") |> range(start: 0) |> filter(fn: (r) => r._measurement == \"{measurement}\") |> delete()'\n",
    "start = datetime.utcfromtimestamp(0)  # Unix epoch start time (1970-01-01 00:00:00 UTC)\n",
    "end = datetime.utcnow() \n",
    "# tables = client.delete_api().delete(start=start, stop=end, predicate = f'_measurement=\"{measurement}\"', bucket=bucket, org=org)\n",
    "\n",
    "flux_result = client.query_api().query(query, org=org)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cd97e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in flux_result:\n",
    "    for record in table.records:\n",
    "        print(record.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d9b73e52",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(flux_result)\n\u001b[0;32m----> 2\u001b[0m df_pivot \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_field\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_value\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_pivot\n",
      "File \u001b[0;32m~/Documents/tradeSmart/venv/lib/python3.11/site-packages/pandas/core/frame.py:8414\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[0;34m(self, columns, index, values)\u001b[0m\n\u001b[1;32m   8409\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   8410\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   8411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpivot\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, columns, index\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mNoDefault, values\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mNoDefault) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   8412\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pivot\n\u001b[0;32m-> 8414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tradeSmart/venv/lib/python3.11/site-packages/pandas/core/reshape/pivot.py:540\u001b[0m, in \u001b[0;36mpivot\u001b[0;34m(data, columns, index, values)\u001b[0m\n\u001b[1;32m    538\u001b[0m         index_list \u001b[38;5;241m=\u001b[39m [Series(data\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname)]\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 540\u001b[0m     index_list \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    542\u001b[0m data_columns \u001b[38;5;241m=\u001b[39m [data[col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_listlike]\n\u001b[1;32m    543\u001b[0m index_list\u001b[38;5;241m.\u001b[39mextend(data_columns)\n",
      "File \u001b[0;32m~/Documents/tradeSmart/venv/lib/python3.11/site-packages/pandas/core/reshape/pivot.py:540\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    538\u001b[0m         index_list \u001b[38;5;241m=\u001b[39m [Series(data\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname)]\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 540\u001b[0m     index_list \u001b[38;5;241m=\u001b[39m [\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m com\u001b[38;5;241m.\u001b[39mconvert_to_list_like(index)]\n\u001b[1;32m    542\u001b[0m data_columns \u001b[38;5;241m=\u001b[39m [data[col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_listlike]\n\u001b[1;32m    543\u001b[0m index_list\u001b[38;5;241m.\u001b[39mextend(data_columns)\n",
      "File \u001b[0;32m~/Documents/tradeSmart/venv/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documents/tradeSmart/venv/lib/python3.11/site-packages/pandas/core/indexes/range.py:349\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: '_time'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(flux_result)\n",
    "df_pivot = df.pivot(index='_time', columns='_field', values='_value')\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "aff8c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6a665163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "eb12f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = asyncio.get_event_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6c2e47ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ast.py:50: RuntimeWarning: coroutine 'execute_parallel' was never awaited\n",
      "  return compile(source, filename, mode, flags,\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m loop\u001b[38;5;241m.\u001b[39mstop()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_forever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py:596\u001b[0m, in \u001b[0;36mBaseEventLoop.run_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run until stop() is called.\"\"\"\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m--> 596\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_coroutine_origin_tracking(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_debug)\n\u001b[1;32m    599\u001b[0m old_agen_hooks \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mget_asyncgen_hooks()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py:588\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_running\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    591\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "loop.stop()\n",
    "loop.run_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e783fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "async def print_hello(input):\n",
    "    time.sleep(1)\n",
    "    print(f'Hello : {input}')\n",
    "    \n",
    "async def using_task_group():\n",
    "    async with asyncio.TaskGroup() as tg:\n",
    "        for i in range(10):\n",
    "            tg.create_task(print_hello(i))\n",
    "    print(\"All tasks have completed now.\")\n",
    "    \n",
    "async def using_gather():\n",
    "    result = await asyncio.gather(*[print_hello(i) for i in range(10)], return_exceptions=True)\n",
    "    \n",
    "async def main():\n",
    "    from datetime import datetime\n",
    "    start = datetime.now()\n",
    "#     await using_task_group()\n",
    "    await using_gather()\n",
    "    end = datetime.now()\n",
    "    td = (end - start).total_seconds() * 10**3\n",
    "    print(f\"Time taken: {td} ms\")\n",
    "\n",
    "# loop = asyncio.get_event_loop()\n",
    "# loop.create_task(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c95ceb81",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'td' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe time of execution of above program is : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtd\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.03f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'td' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"The time of execution of above program is : {td:.03f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86ebc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello : 0\n",
      "Hello : 1\n",
      "Hello : 2\n",
      "Hello : 3\n",
      "Hello : 4\n",
      "Hello : 5\n",
      "Hello : 6\n",
      "Hello : 7\n",
      "Hello : 8\n",
      "Hello : 9\n",
      "The time of execution of above program is : 10036.617ms\n"
     ]
    }
   ],
   "source": [
    "def print_hello(input):\n",
    "    time.sleep(1)\n",
    "    print(f\"Hello : {input}\")\n",
    "\n",
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "for i in range(10):\n",
    "    print_hello(i)\n",
    "end = datetime.now()\n",
    "td = (end - start).total_seconds() * 10**3\n",
    "print(f\"The time of execution of above program is : {td:.03f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4da021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time of execution of above program is : 172.892ms\n"
     ]
    }
   ],
   "source": [
    "print(f\"The time of execution of above program is : {td:.03f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "170e76b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'using_gather' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43musing_gather\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'using_gather' is not defined"
     ]
    }
   ],
   "source": [
    "await using_gather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ee37ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function executed.\n",
      "Function executed.\n",
      "Function executed.\n",
      "Function executed.\n",
      "Function executed.\n",
      "Function executed.\n",
      "Function executed.\n",
      "Function executed.\n",
      "Function executed.\n",
      "Function executed.\n",
      "All functions have completed.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def my_function():\n",
    "    # Simulate a function with a runtime of 1 second\n",
    "    await asyncio.sleep(10)\n",
    "    print(\"Function executed.\")\n",
    "class abc:\n",
    "    async def execute_parallel(self):\n",
    "        tasks = []\n",
    "        for _ in range(10):\n",
    "            task = asyncio.create_task(my_function())\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "await abc().execute_parallel()\n",
    "print(\"All functions have completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20ba6f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Repaired?</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-07-07 09:15:00+05:30</th>\n",
       "      <td>80.449997</td>\n",
       "      <td>80.449997</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 09:16:00+05:30</th>\n",
       "      <td>80.300003</td>\n",
       "      <td>80.300003</td>\n",
       "      <td>80.099998</td>\n",
       "      <td>80.250000</td>\n",
       "      <td>293733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 09:17:00+05:30</th>\n",
       "      <td>80.199997</td>\n",
       "      <td>80.300003</td>\n",
       "      <td>80.099998</td>\n",
       "      <td>80.300003</td>\n",
       "      <td>238919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 09:18:00+05:30</th>\n",
       "      <td>80.300003</td>\n",
       "      <td>80.449997</td>\n",
       "      <td>80.199997</td>\n",
       "      <td>80.400002</td>\n",
       "      <td>213057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 09:19:00+05:30</th>\n",
       "      <td>80.400002</td>\n",
       "      <td>80.449997</td>\n",
       "      <td>80.300003</td>\n",
       "      <td>80.300003</td>\n",
       "      <td>171577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 15:25:00+05:30</th>\n",
       "      <td>79.650002</td>\n",
       "      <td>79.800003</td>\n",
       "      <td>79.550003</td>\n",
       "      <td>79.800003</td>\n",
       "      <td>242367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 15:26:00+05:30</th>\n",
       "      <td>79.750000</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>79.650002</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>110695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 15:27:00+05:30</th>\n",
       "      <td>79.750000</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>79.699997</td>\n",
       "      <td>79.699997</td>\n",
       "      <td>99780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 15:28:00+05:30</th>\n",
       "      <td>79.699997</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>79.650002</td>\n",
       "      <td>79.699997</td>\n",
       "      <td>74575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 15:29:00+05:30</th>\n",
       "      <td>79.699997</td>\n",
       "      <td>79.900002</td>\n",
       "      <td>79.699997</td>\n",
       "      <td>79.699997</td>\n",
       "      <td>94060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  Volume  \\\n",
       "Datetime                                                                        \n",
       "2023-07-07 09:15:00+05:30  80.449997  80.449997  80.000000  80.250000       0   \n",
       "2023-07-07 09:16:00+05:30  80.300003  80.300003  80.099998  80.250000  293733   \n",
       "2023-07-07 09:17:00+05:30  80.199997  80.300003  80.099998  80.300003  238919   \n",
       "2023-07-07 09:18:00+05:30  80.300003  80.449997  80.199997  80.400002  213057   \n",
       "2023-07-07 09:19:00+05:30  80.400002  80.449997  80.300003  80.300003  171577   \n",
       "...                              ...        ...        ...        ...     ...   \n",
       "2023-07-07 15:25:00+05:30  79.650002  79.800003  79.550003  79.800003  242367   \n",
       "2023-07-07 15:26:00+05:30  79.750000  79.750000  79.650002  79.750000  110695   \n",
       "2023-07-07 15:27:00+05:30  79.750000  79.750000  79.699997  79.699997   99780   \n",
       "2023-07-07 15:28:00+05:30  79.699997  79.750000  79.650002  79.699997   74575   \n",
       "2023-07-07 15:29:00+05:30  79.699997  79.900002  79.699997  79.699997   94060   \n",
       "\n",
       "                           Dividends  Stock Splits Repaired?  \n",
       "Datetime                                                      \n",
       "2023-07-07 09:15:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 09:16:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 09:17:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 09:18:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 09:19:00+05:30        0.0           0.0       NaN  \n",
       "...                              ...           ...       ...  \n",
       "2023-07-07 15:25:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 15:26:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 15:27:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 15:28:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 15:29:00+05:30        0.0           0.0       NaN  \n",
       "\n",
       "[375 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "#Data Source\n",
    "import yfinance as yf\n",
    "\n",
    "msft = yf.Ticker(\"IDFCFIRSTB.NS\")\n",
    "# get historical market data\n",
    "hist = msft.history(period=\"1d\", interval=\"1m\",\n",
    "                start=None, end=None, prepost=False, actions=True,\n",
    "                auto_adjust=True, back_adjust=False, repair=True, keepna=False,\n",
    "                proxy=None, rounding=False, timeout=10,\n",
    "                raise_errors=False)\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e5ad5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b5268a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import influxdb_client\n",
    "from influxdb_client import InfluxDBClient, Point\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def influx_function(measurement = None, tag_dict = None, fields_dataframe = None):\n",
    "    if measurement is None or tag_dict is None or fields_dataframe is None:\n",
    "        return {\"success\": False, \"error\": \"Incorrect input Arguments\"}\n",
    "\n",
    "    # Create the write API client\n",
    "    # Set InfluxDB connection details\n",
    "    url = \"http://localhost:8086\"  # Replace with your InfluxDB URL\n",
    "    token = \"c4hEuDHM9LPxNfWH-oFyFfOeIDihTnQx_OEeg99mrd6bZFNa1hEJx7a_aV-cFUH5nWquXUWU5IAeQ975itS4MQ==\"  # Replace with your InfluxDB token\n",
    "    org = \"trade_smart\"  # Replace with your InfluxDB organization\n",
    "    bucket = \"trade_smart\"  # Replace with your InfluxDB bucket\n",
    "    \n",
    "    # Instantiate the InfluxDB client\n",
    "    client = InfluxDBClient(url=url, token=token)\n",
    "    write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "    \n",
    "    # # Convert DataFrame to InfluxDB line protocol format\n",
    "    points = []\n",
    "    for _, row in fields_dataframe.iterrows():\n",
    "        point = Point(\"candlestick\")\n",
    "        for tag_key, tag_value in tag_dict.items():\n",
    "            point.tag(tag_key, tag_value)\n",
    "            \n",
    "        for column, value in row.items():\n",
    "            point.field(column, value)\n",
    "#         point.field(\"open\", row[\"Open\"])\n",
    "#         point.field(\"high\", row[\"High\"])\n",
    "#         point.field(\"low\", row[\"Low\"])\n",
    "#         point.field(\"close\", row[\"Close\"])\n",
    "#         point.field(\"volume\", row[\"Volume\"])\n",
    "        \n",
    "        point.time(_)\n",
    "        points.append(point)\n",
    "    \n",
    "    # [p for p in points]\n",
    "    line_protocol = \"\\n\".join([p.to_line_protocol() for p in points])\n",
    "    return line_protocol\n",
    "    # Write data to InfluxDB\n",
    "#     write_api.write(bucket=bucket, org=org, record=line_protocol)\n",
    "\n",
    "    # Close the connection\n",
    "#     client.close()\n",
    "    \n",
    "def fetch_records():\n",
    "    client = InfluxDBClient(url=url, token=token)\n",
    "    query = f'from(bucket: \"{bucket}\") |> range(start: 0) |> filter(fn: (r) => r._measurement == \"{measurement}\")'\n",
    "    tables = client.query_api().query(query, org=org)\n",
    "    return tables\n",
    "    client.close()\n",
    "\n",
    "def delete_records():\n",
    "    client = InfluxDBClient(url=url, token=token)\n",
    "    delete_query = f'from(bucket: \"{bucket}\") |> range(start: 0) |> filter(fn: (r) => r._measurement == \"{measurement}\") |> delete()'\n",
    "    start = datetime.utcfromtimestamp(0)  # Unix epoch start time (1970-01-01 00:00:00 UTC)\n",
    "    end = datetime.utcnow() \n",
    "    tables = client.delete_api().delete(start=start, stop=end, predicate = f'_measurement=\"{measurement}\"', bucket=bucket, org=org)\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b135f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m influx_function(measurement \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcandlestick\u001b[39m\u001b[38;5;124m'\u001b[39m, tag_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_idfc\u001b[39m\u001b[38;5;124m'\u001b[39m}, fields_dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mhist\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "x = influx_function(measurement = 'candlestick', tag_dict = {'symbol': 'test_idfc'}, fields_dataframe = hist)\n",
    "len(x.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "07b6d9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Processed chunk:\n",
      "100\n",
      "100\n",
      "Processed chunk:\n",
      "100\n",
      "100\n",
      "Processed chunk:\n",
      "100\n",
      "75\n",
      "Processed chunk:\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(hist), 100):\n",
    "    chunk = hist.iloc[i:i+100]\n",
    "    processed_chunk = influx_function(measurement = 'candlestick', tag_dict = {'symbol': 'test_idfc'}, fields_dataframe = chunk)\n",
    "    records = fetch_records()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3576c724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Repaired?</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-07-07 09:15:00+05:30</th>\n",
       "      <td>80.449997</td>\n",
       "      <td>80.449997</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 09:16:00+05:30</th>\n",
       "      <td>80.300003</td>\n",
       "      <td>80.300003</td>\n",
       "      <td>80.099998</td>\n",
       "      <td>80.250000</td>\n",
       "      <td>293733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 09:17:00+05:30</th>\n",
       "      <td>80.199997</td>\n",
       "      <td>80.300003</td>\n",
       "      <td>80.099998</td>\n",
       "      <td>80.300003</td>\n",
       "      <td>238919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 09:18:00+05:30</th>\n",
       "      <td>80.300003</td>\n",
       "      <td>80.449997</td>\n",
       "      <td>80.199997</td>\n",
       "      <td>80.400002</td>\n",
       "      <td>213057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 09:19:00+05:30</th>\n",
       "      <td>80.400002</td>\n",
       "      <td>80.449997</td>\n",
       "      <td>80.300003</td>\n",
       "      <td>80.300003</td>\n",
       "      <td>171577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 15:25:00+05:30</th>\n",
       "      <td>79.650002</td>\n",
       "      <td>79.800003</td>\n",
       "      <td>79.550003</td>\n",
       "      <td>79.800003</td>\n",
       "      <td>242367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 15:26:00+05:30</th>\n",
       "      <td>79.750000</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>79.650002</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>110695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 15:27:00+05:30</th>\n",
       "      <td>79.750000</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>79.699997</td>\n",
       "      <td>79.699997</td>\n",
       "      <td>99780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 15:28:00+05:30</th>\n",
       "      <td>79.699997</td>\n",
       "      <td>79.750000</td>\n",
       "      <td>79.650002</td>\n",
       "      <td>79.699997</td>\n",
       "      <td>74575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07 15:29:00+05:30</th>\n",
       "      <td>79.699997</td>\n",
       "      <td>79.900002</td>\n",
       "      <td>79.699997</td>\n",
       "      <td>79.699997</td>\n",
       "      <td>94060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  Volume  \\\n",
       "Datetime                                                                        \n",
       "2023-07-07 09:15:00+05:30  80.449997  80.449997  80.000000  80.250000       0   \n",
       "2023-07-07 09:16:00+05:30  80.300003  80.300003  80.099998  80.250000  293733   \n",
       "2023-07-07 09:17:00+05:30  80.199997  80.300003  80.099998  80.300003  238919   \n",
       "2023-07-07 09:18:00+05:30  80.300003  80.449997  80.199997  80.400002  213057   \n",
       "2023-07-07 09:19:00+05:30  80.400002  80.449997  80.300003  80.300003  171577   \n",
       "...                              ...        ...        ...        ...     ...   \n",
       "2023-07-07 15:25:00+05:30  79.650002  79.800003  79.550003  79.800003  242367   \n",
       "2023-07-07 15:26:00+05:30  79.750000  79.750000  79.650002  79.750000  110695   \n",
       "2023-07-07 15:27:00+05:30  79.750000  79.750000  79.699997  79.699997   99780   \n",
       "2023-07-07 15:28:00+05:30  79.699997  79.750000  79.650002  79.699997   74575   \n",
       "2023-07-07 15:29:00+05:30  79.699997  79.900002  79.699997  79.699997   94060   \n",
       "\n",
       "                           Dividends  Stock Splits Repaired?  \n",
       "Datetime                                                      \n",
       "2023-07-07 09:15:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 09:16:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 09:17:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 09:18:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 09:19:00+05:30        0.0           0.0       NaN  \n",
       "...                              ...           ...       ...  \n",
       "2023-07-07 15:25:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 15:26:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 15:27:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 15:28:00+05:30        0.0           0.0       NaN  \n",
       "2023-07-07 15:29:00+05:30        0.0           0.0       NaN  \n",
       "\n",
       "[375 rows x 8 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "40069212",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_result = fetch_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a663dd85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_field                         close       high        low       open  \\\n",
      "_time                                                                   \n",
      "2023-07-07 03:45:00+00:00  80.250000  80.449997  80.000000  80.449997   \n",
      "2023-07-07 03:46:00+00:00  80.250000  80.300003  80.099998  80.300003   \n",
      "2023-07-07 03:47:00+00:00  80.300003  80.300003  80.099998  80.199997   \n",
      "2023-07-07 03:48:00+00:00  80.400002  80.449997  80.199997  80.300003   \n",
      "2023-07-07 03:49:00+00:00  80.300003  80.449997  80.300003  80.400002   \n",
      "...                              ...        ...        ...        ...   \n",
      "2023-07-07 09:55:00+00:00  79.800003  79.800003  79.550003  79.650002   \n",
      "2023-07-07 09:56:00+00:00  79.750000  79.750000  79.650002  79.750000   \n",
      "2023-07-07 09:57:00+00:00  79.699997  79.750000  79.699997  79.750000   \n",
      "2023-07-07 09:58:00+00:00  79.699997  79.750000  79.650002  79.699997   \n",
      "2023-07-07 09:59:00+00:00  79.699997  79.900002  79.699997  79.699997   \n",
      "\n",
      "_field                       volume  \n",
      "_time                                \n",
      "2023-07-07 03:45:00+00:00       0.0  \n",
      "2023-07-07 03:46:00+00:00  293733.0  \n",
      "2023-07-07 03:47:00+00:00  238919.0  \n",
      "2023-07-07 03:48:00+00:00  213057.0  \n",
      "2023-07-07 03:49:00+00:00  171577.0  \n",
      "...                             ...  \n",
      "2023-07-07 09:55:00+00:00  242367.0  \n",
      "2023-07-07 09:56:00+00:00  110695.0  \n",
      "2023-07-07 09:57:00+00:00   99780.0  \n",
      "2023-07-07 09:58:00+00:00   74575.0  \n",
      "2023-07-07 09:59:00+00:00   94060.0  \n",
      "\n",
      "[375 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract time, field, and value from the Flux result\n",
    "time_values = []\n",
    "field_values = []\n",
    "value_values = []\n",
    "\n",
    "for item in flux_result:\n",
    "    for record in item:\n",
    "        time_values.append(record.values['_time'])\n",
    "        field_values.append(record.values['_field'])\n",
    "        value_values.append(record.values['_value'])\n",
    "\n",
    "# Create a DataFrame from the extracted values\n",
    "df = pd.DataFrame({'_time': time_values, '_field': field_values, '_value': value_values})\n",
    "\n",
    "# Pivot DataFrame to have fields as columns\n",
    "df_pivot = df.pivot(index='_time', columns='_field', values='_value')\n",
    "\n",
    "print(df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c9c85f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>_field</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>375.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79.683734</td>\n",
       "      <td>79.711600</td>\n",
       "      <td>79.637467</td>\n",
       "      <td>79.683867</td>\n",
       "      <td>72613.368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.376111</td>\n",
       "      <td>0.381497</td>\n",
       "      <td>0.369133</td>\n",
       "      <td>0.377297</td>\n",
       "      <td>67411.473535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>79.050003</td>\n",
       "      <td>79.099998</td>\n",
       "      <td>79.050003</td>\n",
       "      <td>79.050003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>79.400002</td>\n",
       "      <td>79.449997</td>\n",
       "      <td>79.400002</td>\n",
       "      <td>79.400002</td>\n",
       "      <td>26478.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79.599998</td>\n",
       "      <td>79.599998</td>\n",
       "      <td>79.550003</td>\n",
       "      <td>79.599998</td>\n",
       "      <td>50721.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79.900002</td>\n",
       "      <td>79.949997</td>\n",
       "      <td>79.849998</td>\n",
       "      <td>79.900002</td>\n",
       "      <td>94123.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.750000</td>\n",
       "      <td>80.800003</td>\n",
       "      <td>80.699997</td>\n",
       "      <td>80.750000</td>\n",
       "      <td>423819.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "_field       close        high         low        open         volume\n",
       "count   375.000000  375.000000  375.000000  375.000000     375.000000\n",
       "mean     79.683734   79.711600   79.637467   79.683867   72613.368000\n",
       "std       0.376111    0.381497    0.369133    0.377297   67411.473535\n",
       "min      79.050003   79.099998   79.050003   79.050003       0.000000\n",
       "25%      79.400002   79.449997   79.400002   79.400002   26478.500000\n",
       "50%      79.599998   79.599998   79.550003   79.599998   50721.000000\n",
       "75%      79.900002   79.949997   79.849998   79.900002   94123.500000\n",
       "max      80.750000   80.800003   80.699997   80.750000  423819.000000"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed4711a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bff6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fetch_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80598ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x:\n",
    "    for j in i:\n",
    "        print("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
